import requests
from bs4 import BeautifulSoup
import re
import time

# HEADERS padr√£o para todas as fun√ß√µes
HEADERS = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'}

def scraper_plaza_chapeco():
    """
    Scraper refinado para Plaza Chapec√≥
    Extrai: c√≥digo, t√≠tulo, pre√ßo, √°rea, quartos, banheiros, vagas, endere√ßo, tipo de neg√≥cio
    STATUS: ‚úÖ FUNCIONANDO
    """
    imoveis_encontrados = []
    
    # URLs para aluguel e venda
    urls = [
        ("https://plazachapeco.com.br/alugar-imoveis-chapeco-sc/", "LOCA√á√ÉO"),
        ("https://plazachapeco.com.br/comprar-imoveis-chapeco-sc/", "VENDA")
    ]
    
    for url, tipo_negocio in urls:
        try:
            response = requests.get(url, headers=HEADERS, timeout=20)
            response.raise_for_status()
        except requests.exceptions.RequestException as e:
            print(f"Erro ao acessar {url}: {e}")
            continue

        soup = BeautifulSoup(response.content, 'html.parser')
        
        # Seletor espec√≠fico: links que cont√™m "/imovel/" na URL
        cards_de_imoveis = soup.find_all('a', href=re.compile(r'/imovel/'))
        
        print(f"Encontrados {len(cards_de_imoveis)} im√≥veis na Plaza Chapec√≥ ({tipo_negocio}). Processando...")

        for card in cards_de_imoveis:
            try:
                # URL completa
                url_imovel = card.get('href', '')
                if url_imovel.startswith('/'):
                    url_imovel = 'https://plazachapeco.com.br' + url_imovel
                
                # C√≥digo do im√≥vel (extra√≠do da URL)
                codigo_match = re.search(r'/imovel/(\d+)/', url_imovel)
                codigo = codigo_match.group(1) if codigo_match else ""
                
                # T√≠tulo (classe espec√≠fica identificada)
                titulo_elem = card.find(class_='chamadaimovel')
                titulo = titulo_elem.get_text().strip() if titulo_elem else ""
                
                # Pre√ßo (classe espec√≠fica identificada)
                preco_elem = card.find(class_='valorimovel')
                preco = preco_elem.get_text().strip() if preco_elem else ""
                
                # Caracter√≠sticas (√°rea, quartos, banheiros, vagas)
                caracteristicas_elem = card.find(class_='caracteristicas')
                area = quartos = banheiros = vagas = ""
                
                if caracteristicas_elem:
                    carac_text = caracteristicas_elem.get_text()
                    
                    # Extrair √°rea
                    area_match = re.search(r'(\d+)m¬≤', carac_text)
                    area = area_match.group(1) + 'm¬≤' if area_match else ""
                    
                    # Extrair quartos
                    quartos_match = re.search(r'(\d+)\s+quartos?', carac_text)
                    quartos = quartos_match.group(1) if quartos_match else ""
                    
                    # Extrair banheiros
                    banheiros_match = re.search(r'(\d+)\s+banheiros?', carac_text)
                    banheiros = banheiros_match.group(1) if banheiros_match else ""
                    
                    # Extrair vagas
                    vagas_match = re.search(r'(\d+)\s+vagas?', carac_text)
                    vagas = vagas_match.group(1) if vagas_match else ""
                
                # Endere√ßo (classe espec√≠fica identificada)
                endereco_elem = card.find(class_='enderecoimovel')
                endereco = endereco_elem.get_text().strip() if endereco_elem else ""
                
                # Tipo do im√≥vel (extra√≠do do t√≠tulo)
                tipo_imovel = ""
                if titulo:
                    if 'apartamento' in titulo.lower():
                        tipo_imovel = "Apartamento"
                    elif 'casa' in titulo.lower():
                        tipo_imovel = "Casa"
                    elif 'sala comercial' in titulo.lower():
                        tipo_imovel = "Sala Comercial"
                    elif 'terreno' in titulo.lower():
                        tipo_imovel = "Terreno"
                    elif 'pr√©dio' in titulo.lower():
                        tipo_imovel = "Pr√©dio"
                    elif 'barrac√£o' in titulo.lower():
                        tipo_imovel = "Barrac√£o"
                
                if titulo and codigo:  # S√≥ adiciona se tiver dados essenciais
                    imoveis_encontrados.append({
                        "imobiliaria": "Plaza Chapec√≥",
                        "codigo": codigo,
                        "titulo": titulo,
                        "tipo_imovel": tipo_imovel,
                        "preco": preco,
                        "area": area,
                        "quartos": quartos,
                        "banheiros": banheiros,
                        "vagas": vagas,
                        "endereco": endereco,
                        "tipo_negocio": tipo_negocio,
                        "url": url_imovel
                    })
                    
            except Exception as e:
                print(f"Erro ao processar um card da Plaza Chapec√≥: {e}")
                continue

    return imoveis_encontrados


def scraper_casa_imoveis():
    """
    Scraper refinado para Casa Im√≥veis
    Extrai dados do texto estruturado dos links
    STATUS: ‚úÖ FUNCIONANDO
    """
    imoveis_encontrados = []
    
    # URLs para aluguel (venda usa filtros)
    urls = [
        ("https://www.casaimoveis.net/alugue-um-imovel", "LOCA√á√ÉO")
    ]
    
    for url, tipo_negocio in urls:
        try:
            response = requests.get(url, headers=HEADERS, timeout=20)
            response.raise_for_status()
        except requests.exceptions.RequestException as e:
            print(f"Erro ao acessar {url}: {e}")
            continue

        soup = BeautifulSoup(response.content, 'html.parser')
        
        # Buscar links que seguem o padr√£o "Tipo - C√≥digo Bairro - Cidade"
        all_links = soup.find_all('a', href=True)
        cards_relevantes = []
        
        for link in all_links:
            text = link.get_text().strip()
            # Padr√£o: "Tipo - C√≥digo Bairro - Cidade √Årea Quartos R$ Pre√ßo"
            if re.match(r'^(Apartamento|Casa|Terreno|Sala comercial|Barrac√£o)\s+-\s+\d+', text) and 'R$' in text:
                cards_relevantes.append(link)
        
        print(f"Encontrados {len(cards_relevantes)} im√≥veis na Casa Im√≥veis ({tipo_negocio}). Processando...")

        for card in cards_relevantes:
            try:
                text = card.get_text().strip()
                url_imovel = card.get('href', '')
                
                # Garantir URL absoluta
                if url_imovel.startswith('/'):
                    url_imovel = 'https://www.casaimoveis.net' + url_imovel
                
                # Extrair tipo e c√≥digo
                tipo_codigo_match = re.match(r'^(\w+(?:\s+\w+)*)\s+-\s+(\d+)', text)
                tipo_imovel = tipo_codigo_match.group(1) if tipo_codigo_match else ""
                codigo = tipo_codigo_match.group(2) if tipo_codigo_match else ""
                
                # Extrair bairro
                bairro_match = re.search(r'(\w+(?:\s+\w+)*)\s+-\s+Chapec√≥', text)
                bairro = bairro_match.group(1) if bairro_match else ""
                endereco = f"{bairro} - Chapec√≥, SC" if bairro else "Chapec√≥, SC"
                
                # Extrair √°rea
                area_match = re.search(r'([\d.,]+)m¬≤', text)
                area = area_match.group(1) + 'm¬≤' if area_match else ""
                
                # Extrair quartos
                quartos_match = re.search(r'(\d+)\s+quarto', text)
                quartos = quartos_match.group(1) if quartos_match else ""
                
                # Extrair banheiros
                banheiros_match = re.search(r'(\d+)\s+banheiro', text)
                banheiros = banheiros_match.group(1) if banheiros_match else ""
                
                # Extrair vagas
                vagas_match = re.search(r'(\d+)\s+vaga', text)
                vagas = vagas_match.group(1) if vagas_match else ""
                
                # Extrair pre√ßo
                preco_match = re.search(r'R\$\s*([\d.,]+)', text)
                preco = 'R$ ' + preco_match.group(1) if preco_match else ""
                
                if codigo and tipo_imovel:  # S√≥ adiciona se tiver dados essenciais
                    imoveis_encontrados.append({
                        "imobiliaria": "Casa Im√≥veis",
                        "codigo": codigo,
                        "titulo": text,
                        "tipo_imovel": tipo_imovel,
                        "preco": preco,
                        "area": area,
                        "quartos": quartos,
                        "banheiros": banheiros,
                        "vagas": vagas,
                        "endereco": endereco,
                        "tipo_negocio": tipo_negocio,
                        "url": url_imovel
                    })
                    
            except Exception as e:
                print(f"Erro ao processar um card da Casa Im√≥veis: {e}")
                continue

    return imoveis_encontrados


def scraper_santa_maria():
    """
    Scraper CORRIGIDO para Santa Maria
    Baseado na an√°lise profunda do HTML - SELETORES CSS CORRIGIDOS
    STATUS: üîß CORRIGIDO
    """
    imoveis_encontrados = []
    
    # URLs para aluguel
    urls = [
        ("https://santamaria.com.br/alugar", "LOCA√á√ÉO")
    ]
    
    for url, tipo_negocio in urls:
        try:
            print(f"Acessando {url}...")
            response = requests.get(url, headers=HEADERS, timeout=30)
            response.raise_for_status()
            
            # Aguardar JavaScript carregar
            time.sleep(5)  # Aumentado de 3 para 5 segundos
            
        except requests.exceptions.RequestException as e:
            print(f"Erro ao acessar {url}: {e}")
            continue

        soup = BeautifulSoup(response.content, 'html.parser')
        
        # CORRE√á√ÉO: Seletores CSS corretos (com espa√ßos, n√£o pontos)
        # 1. Buscar c√≥digos dos im√≥veis
        codigos_elements = soup.find_all('span', class_='sc-902a1a30-11 hjZxig')
        print(f"C√≥digos encontrados: {len(codigos_elements)}")
        
        # 2. Buscar pre√ßos de aluguel
        precos_aluguel = soup.find_all('span', class_='sc-902a1a30-17 fuGSiV')
        print(f"Pre√ßos de aluguel encontrados: {len(precos_aluguel)}")
        
        # 3. Buscar caracter√≠sticas (√°rea, quartos, etc.)
        caracteristicas = soup.find_all('ul', class_='sc-902a1a30-20 kGQWoW')
        print(f"Listas de caracter√≠sticas encontradas: {len(caracteristicas)}")
        
        # 4. Buscar links dos im√≥veis
        links_imoveis = soup.find_all('a', href=re.compile(r'/imovel/'))
        print(f"Links de im√≥veis encontrados: {len(links_imoveis)}")
        
        # Processar cada im√≥vel baseado nos c√≥digos encontrados
        for i, codigo_elem in enumerate(codigos_elements):
            try:
                # Extrair c√≥digo
                codigo = codigo_elem.get_text().strip()
                
                # Determinar tipo do im√≥vel baseado no c√≥digo
                if codigo.startswith('CA'):
                    tipo_imovel = "Casa"
                elif codigo.startswith('AP'):
                    tipo_imovel = "Apartamento"
                else:
                    tipo_imovel = "Im√≥vel"
                
                # Extrair pre√ßo de aluguel (se dispon√≠vel)
                preco_aluguel = ""
                if i < len(precos_aluguel):
                    preco_aluguel = precos_aluguel[i].get_text().strip()
                
                # Usar pre√ßo de aluguel como pre√ßo principal
                preco = preco_aluguel
                
                # Extrair caracter√≠sticas (√°rea, quartos, banheiros, vagas)
                area = quartos = banheiros = vagas = ""
                if i < len(caracteristicas):
                    carac_items = caracteristicas[i].find_all('li', class_='sc-902a1a30-21 eCXFMG')
                    
                    for j, item in enumerate(carac_items):
                        item_text = item.get_text().strip()
                        
                        if j == 0:  # Primeiro item: √°rea
                            area_match = re.search(r'(\d+)\s*m¬≤', item_text)
                            area = area_match.group(1) + 'm¬≤' if area_match else ""
                        elif j == 1:  # Segundo item: quartos
                            quartos_match = re.search(r'(\d+)\s*dor', item_text)
                            quartos = quartos_match.group(1) if quartos_match else ""
                        elif j == 2:  # Terceiro item: banheiros
                            banheiros_match = re.search(r'(\d+)\s*ban', item_text)
                            banheiros = banheiros_match.group(1) if banheiros_match else ""
                        elif j == 3:  # Quarto item: vagas
                            vagas_match = re.search(r'(\d+)\s*vaga', item_text)
                            vagas = vagas_match.group(1) if vagas_match else ""
                
                # Buscar URL do im√≥vel correspondente
                url_imovel = ""
                if i < len(links_imoveis):
                    url_imovel = links_imoveis[i].get('href', '')
                    if url_imovel.startswith('/'):
                        url_imovel = 'https://santamaria.com.br' + url_imovel
                
                # Extrair bairro da URL
                bairro = ""
                if url_imovel:
                    # Padr√£o: /imovel/tipo-codigo-smi-bairro
                    url_parts = url_imovel.split('/')
                    if len(url_parts) > 2:
                        last_part = url_parts[-1]
                        # Extrair bairro (√∫ltima parte ap√≥s √∫ltimo h√≠fen)
                        parts = last_part.split('-')
                        if len(parts) > 3:
                            bairro = parts[-1].replace('-', ' ').title()
                
                endereco = f"{bairro} - Chapec√≥, SC" if bairro else "Chapec√≥, SC"
                
                # T√≠tulo baseado nas informa√ß√µes
                titulo = f"{tipo_imovel} {codigo} - {bairro}" if bairro else f"{tipo_imovel} {codigo}"
                
                if codigo:  # S√≥ adiciona se tiver c√≥digo
                    imoveis_encontrados.append({
                        "imobiliaria": "Santa Maria",
                        "codigo": codigo,
                        "titulo": titulo,
                        "tipo_imovel": tipo_imovel,
                        "preco": preco,
                        "area": area,
                        "quartos": quartos,
                        "banheiros": banheiros,
                        "vagas": vagas,
                        "endereco": endereco,
                        "tipo_negocio": tipo_negocio,
                        "url": url_imovel
                    })
                    
            except Exception as e:
                print(f"Erro ao processar im√≥vel {i} da Santa Maria: {e}")
                continue

    print(f"Santa Maria: {len(imoveis_encontrados)} im√≥veis coletados")
    return imoveis_encontrados


def scraper_formiga_imoveis():
    """
    Scraper CORRIGIDO para Formiga Im√≥veis
    Baseado na an√°lise profunda - timeout aumentado
    STATUS: üîß CORRIGIDO
    """
    imoveis_encontrados = []
    
    # URLs para venda e lan√ßamentos
    urls = [
        ("https://www.formigaimoveis.com.br/venda", "VENDA"),
        ("https://www.formigaimoveis.com.br/lancamentos", "LAN√áAMENTO")
    ]
    
    for url, tipo_negocio in urls:
        try:
            print(f"Acessando {url}...")
            response = requests.get(url, headers=HEADERS, timeout=30)
            response.raise_for_status()
            
            # CORRE√á√ÉO: Aumentar timeout para JavaScript carregar
            time.sleep(5)  # Aumentado de 3 para 5 segundos
            
        except requests.exceptions.RequestException as e:
            print(f"Erro ao acessar {url}: {e}")
            continue

        soup = BeautifulSoup(response.content, 'html.parser')
        
        # Seletores espec√≠ficos (j√° estavam corretos)
        # 1. Buscar c√≥digos dos im√≥veis
        codigos_elements = soup.find_all('span', class_='card-buttons_code__LsI0q')
        print(f"C√≥digos encontrados: {len(codigos_elements)}")
        
        # CORRE√á√ÉO: Verificar se elementos foram encontrados
        if not codigos_elements:
            print("Nenhum c√≥digo encontrado - p√°gina pode n√£o ter carregado completamente")
            continue
        
        # 2. Buscar pre√ßos
        precos_elements = soup.find_all('span', class_='contracts_priceNumber__WhudD')
        print(f"Pre√ßos encontrados: {len(precos_elements)}")
        
        # 3. Buscar tipos de im√≥veis
        tipos_elements = soup.find_all('span', class_='vertical-property-card_type__wZ3CC')
        print(f"Tipos encontrados: {len(tipos_elements)}")
        
        # 4. Buscar links dos im√≥veis
        links_imoveis = soup.find_all('a', href=re.compile(r'/imovel/'))
        print(f"Links de im√≥veis encontrados: {len(links_imoveis)}")
        
        # Processar cada im√≥vel baseado nos c√≥digos encontrados
        for i, codigo_elem in enumerate(codigos_elements):
            try:
                # Extrair c√≥digo (remover "C√≥d. ")
                codigo_text = codigo_elem.get_text().strip()
                codigo_match = re.search(r'C√≥d\.\s*(\d+)', codigo_text)
                codigo = codigo_match.group(1) if codigo_match else ""
                
                # Extrair tipo do im√≥vel
                tipo_imovel = ""
                if i < len(tipos_elements):
                    tipo_imovel = tipos_elements[i].get_text().strip()
                
                # Extrair pre√ßo
                preco = ""
                if i < len(precos_elements):
                    preco = precos_elements[i].get_text().strip()
                
                # Buscar URL do im√≥vel correspondente
                url_imovel = ""
                # CORRE√á√ÉO: Buscar link que contenha o c√≥digo espec√≠fico
                for link in links_imoveis:
                    href = link.get('href', '')
                    if codigo in href:
                        url_imovel = href
                        if url_imovel.startswith('/'):
                            url_imovel = 'https://www.formigaimoveis.com.br' + url_imovel
                        break
                
                # Extrair informa√ß√µes da URL ou do card
                bairro = cidade = ""
                area = quartos = banheiros = vagas = ""
                
                if url_imovel:
                    # Padr√£o: /imovel/tipo-bairro-cidade-codigo
                    url_parts = url_imovel.split('/')
                    if len(url_parts) > 2:
                        last_part = url_parts[-2]  # Pen√∫ltima parte
                        # Tentar extrair bairro da URL
                        if 'jardim-italia' in last_part:
                            bairro = "Jardim It√°lia"
                        elif 'centro' in last_part:
                            bairro = "Centro"
                        elif 'presidente-medici' in last_part:
                            bairro = "Presidente M√©dici"
                        else:
                            # Extrair bairro gen√©rico
                            parts = last_part.split('-')
                            if len(parts) >= 2:
                                bairro = ' '.join(parts[1:3]).title()
                
                # Se n√£o conseguiu extrair da URL, usar padr√µes
                if not bairro:
                    bairro = "Chapec√≥"
                
                endereco = f"{bairro} - SC"
                
                # CORRE√á√ÉO: Buscar caracter√≠sticas no card correspondente
                if i < len(links_imoveis):
                    # Encontrar o link que corresponde a este c√≥digo
                    card_correspondente = None
                    for link in links_imoveis:
                        if codigo in link.get('href', ''):
                            card_correspondente = link
                            break
                    
                    if card_correspondente:
                        card_text = card_correspondente.get_text()
                        
                        # Extrair √°rea
                        area_match = re.search(r'(\d+)m¬≤', card_text)
                        area = area_match.group(1) + 'm¬≤' if area_match else ""
                        
                        # Extrair quartos
                        quartos_match = re.search(r'(\d+)\s*quartos?', card_text)
                        quartos = quartos_match.group(1) if quartos_match else ""
                        
                        # Extrair banheiros
                        banheiros_match = re.search(r'(\d+)\s*banheiros?', card_text)
                        banheiros = banheiros_match.group(1) if banheiros_match else ""
                        
                        # Extrair vagas
                        vagas_match = re.search(r'(\d+)\s*vagas?', card_text)
                        vagas = vagas_match.group(1) if vagas_match else ""
                
                # T√≠tulo baseado nas informa√ß√µes
                titulo = f"{tipo_imovel} C√≥d. {codigo} - {bairro}" if tipo_imovel and bairro else f"Im√≥vel C√≥d. {codigo}"
                
                if codigo:  # S√≥ adiciona se tiver c√≥digo
                    imoveis_encontrados.append({
                        "imobiliaria": "Formiga Im√≥veis",
                        "codigo": codigo,
                        "titulo": titulo,
                        "tipo_imovel": tipo_imovel,
                        "preco": preco,
                        "area": area,
                        "quartos": quartos,
                        "banheiros": banheiros,
                        "vagas": vagas,
                        "endereco": endereco,
                        "tipo_negocio": tipo_negocio,
                        "url": url_imovel
                    })
                    
            except Exception as e:
                print(f"Erro ao processar im√≥vel {i} da Formiga Im√≥veis: {e}")
                continue

    print(f"Formiga Im√≥veis: {len(imoveis_encontrados)} im√≥veis coletados")
    return imoveis_encontrados


def scraper_mobg():
    """
    Scraper refinado para MOBG
    Extrai dados dos cards com carrossel de imagens
    STATUS: ‚úÖ FUNCIONANDO
    """
    URL = "https://mobg.com.br/"
    
    try:
        response = requests.get(URL, headers=HEADERS, timeout=20)
        response.raise_for_status()
    except requests.exceptions.RequestException as e:
        print(f"Erro ao acessar a p√°gina da MOBG: {e}")
        return []

    soup = BeautifulSoup(response.content, 'html.parser')
    imoveis_encontrados = []
    
    # Buscar por links que contenham informa√ß√µes de pre√ßo e c√≥digo
    all_links = soup.find_all('a', href=True)
    cards_relevantes = []
    
    for link in all_links:
        text = link.get_text().strip()
        # Padr√£o: "R$ X.XXX R$ X.XXX total #XXXX Tipo ‚Ä¢ Bairro ‚Ä¢ Cidade"
        if 'R$' in text and '#' in text and ('Apartamento' in text or 'Casa' in text):
            cards_relevantes.append(link)
    
    print(f"Encontrados {len(cards_relevantes)} im√≥veis na MOBG. Processando...")

    for card in cards_relevantes:
        try:
            text = card.get_text().strip()
            url_imovel = card.get('href', '')
            
            # Garantir URL absoluta
            if url_imovel.startswith('/'):
                url_imovel = 'https://mobg.com.br' + url_imovel
            
            # Extrair pre√ßos
            precos = re.findall(r'R\$\s*([\d.,]+)', text)
            preco_principal = 'R$ ' + precos[0] if precos else ""
            
            # Extrair c√≥digo
            codigo_match = re.search(r'#(\d+)', text)
            codigo = codigo_match.group(1) if codigo_match else ""
            
            # Extrair tipo do im√≥vel
            tipo_match = re.search(r'#\d+\s*([^‚Ä¢]+)', text)
            tipo_imovel = tipo_match.group(1).strip() if tipo_match else ""
            
            # Extrair localiza√ß√£o
            localizacao_parts = text.split('‚Ä¢')
            bairro = cidade = ""
            if len(localizacao_parts) >= 2:
                bairro = localizacao_parts[1].strip()
            if len(localizacao_parts) >= 3:
                cidade_part = localizacao_parts[2].strip()
                # Extrair apenas a cidade, ignorando outras informa√ß√µes
                cidade_match = re.search(r'^([^0-9R$]+)', cidade_part)
                cidade = cidade_match.group(1).strip() if cidade_match else cidade_part
            
            endereco = f"{bairro} - {cidade}" if bairro and cidade else "Chapec√≥, SC"
            
            # Extrair caracter√≠sticas
            area_match = re.search(r'(\d+)m¬≤', text)
            area = area_match.group(1) + 'm¬≤' if area_match else ""
            
            quartos_match = re.search(r'(\d+)\s*quartos?', text)
            quartos = quartos_match.group(1) if quartos_match else ""
            
            banheiros_match = re.search(r'(\d+)\s*banheiros?', text)
            banheiros = banheiros_match.group(1) if banheiros_match else ""
            
            vagas_match = re.search(r'(\d+)\s*vagas?', text)
            vagas = vagas_match.group(1) if vagas_match else ""
            
            # Determinar tipo de neg√≥cio baseado na URL ou texto
            tipo_negocio = "LOCA√á√ÉO"  # Padr√£o para MOBG
            if 'venda' in url_imovel.lower() or 'comprar' in text.lower():
                tipo_negocio = "VENDA"
            
            # T√≠tulo baseado nas informa√ß√µes extra√≠das
            titulo = f"{tipo_imovel} #{codigo} - {bairro}" if tipo_imovel and bairro else f"Im√≥vel #{codigo}"
            
            if codigo or preco_principal:  # Adiciona se tiver pelo menos c√≥digo ou pre√ßo
                imoveis_encontrados.append({
                    "imobiliaria": "MOBG",
                    "codigo": codigo,
                    "titulo": titulo,
                    "tipo_imovel": tipo_imovel,
                    "preco": preco_principal,
                    "area": area,
                    "quartos": quartos,
                    "banheiros": banheiros,
                    "vagas": vagas,
                    "endereco": endereco,
                    "tipo_negocio": tipo_negocio,
                    "url": url_imovel
                })
                
        except Exception as e:
            print(f"Erro ao processar um card da MOBG: {e}")
            continue

    return imoveis_encontrados


def scraper_smart_aluguel_venda():
    """
    Scraper refinado para Smart Aluguel e Venda
    STATUS: ‚úÖ FUNCIONANDO
    """
    imoveis_encontrados = []
    
    # URLs espec√≠ficas para aluguel e venda
    urls = [
        ("https://www.smartaluguelevenda.com.br/alugar/todos", "LOCA√á√ÉO"),
        ("https://www.smartaluguelevenda.com.br/comprar/todos", "VENDA")
    ]
    
    for url, tipo_negocio in urls:
        try:
            response = requests.get(url, headers=HEADERS, timeout=20)
            response.raise_for_status()
        except requests.exceptions.RequestException as e:
            print(f"Erro ao acessar {url}: {e}")
            continue

        soup = BeautifulSoup(response.content, 'html.parser')
        
        # Buscar por padr√µes mais amplos
        all_links = soup.find_all('a', href=True)
        cards_relevantes = []
        
        for link in all_links:
            text = link.get_text().strip()
            href = link.get('href', '')
            
            # Crit√©rios mais amplos para identificar cards de im√≥veis
            if (len(text) > 30 and 
                ('R$' in text or 'm¬≤' in text or 'quarto' in text) and
                (href.startswith('/') or 'smartaluguelevenda' in href)):
                cards_relevantes.append(link)
        
        print(f"Encontrados {len(cards_relevantes)} im√≥veis na Smart ({tipo_negocio}). Processando...")

        for card in cards_relevantes:
            try:
                text = card.get_text().strip()
                url_imovel = card.get('href', '')
                
                # Garantir URL absoluta
                if url_imovel.startswith('/'):
                    url_imovel = 'https://www.smartaluguelevenda.com.br' + url_imovel
                
                # Extrair c√≥digo da URL ou texto
                codigo = ""
                codigo_url_match = re.search(r'/imovel/(\d+)', url_imovel)
                if codigo_url_match:
                    codigo = codigo_url_match.group(1)
                else:
                    # Tentar extrair c√≥digo do texto
                    codigo_text_match = re.search(r'#(\d+)|cod[igo]*[:\s]*(\d+)', text, re.IGNORECASE)
                    if codigo_text_match:
                        codigo = codigo_text_match.group(1) or codigo_text_match.group(2)
                
                # Extrair tipo do im√≥vel
                tipo_imovel = ""
                if 'apartamento' in text.lower():
                    tipo_imovel = "Apartamento"
                elif 'casa' in text.lower():
                    tipo_imovel = "Casa"
                elif 'sala' in text.lower():
                    tipo_imovel = "Sala Comercial"
                elif 'terreno' in text.lower():
                    tipo_imovel = "Terreno"
                
                # Extrair pre√ßo
                preco_match = re.search(r'R\$\s*([\d.,]+)', text)
                preco = 'R$ ' + preco_match.group(1) if preco_match else ""
                
                # Extrair √°rea
                area_match = re.search(r'(\d+)m¬≤', text)
                area = area_match.group(1) + 'm¬≤' if area_match else ""
                
                # Extrair quartos
                quartos_match = re.search(r'(\d+)\s*quartos?', text)
                quartos = quartos_match.group(1) if quartos_match else ""
                
                # Extrair banheiros
                banheiros_match = re.search(r'(\d+)\s*banheiros?', text)
                banheiros = banheiros_match.group(1) if banheiros_match else ""
                
                # Extrair vagas
                vagas_match = re.search(r'(\d+)\s*vagas?', text)
                vagas = vagas_match.group(1) if vagas_match else ""
                
                # Extrair endere√ßo/bairro
                endereco = "Chapec√≥, SC"  # Padr√£o
                bairro_patterns = ['Centro', 'Efapi', 'Jardim It√°lia', 'Pinheirinho', 'Santo Ant√¥nio']
                for bairro in bairro_patterns:
                    if bairro.lower() in text.lower():
                        endereco = f"{bairro} - Chapec√≥, SC"
                        break
                
                # T√≠tulo baseado nas informa√ß√µes dispon√≠veis
                titulo = text[:100] + "..." if len(text) > 100 else text
                
                if codigo or preco:  # Adiciona se tiver pelo menos c√≥digo ou pre√ßo
                    imoveis_encontrados.append({
                        "imobiliaria": "Smart Aluguel e Venda",
                        "codigo": codigo,
                        "titulo": titulo,
                        "tipo_imovel": tipo_imovel,
                        "preco": preco,
                        "area": area,
                        "quartos": quartos,
                        "banheiros": banheiros,
                        "vagas": vagas,
                        "endereco": endereco,
                        "tipo_negocio": tipo_negocio,
                        "url": url_imovel
                    })
                    
            except Exception as e:
                print(f"Erro ao processar um card da Smart: {e}")
                continue

    return imoveis_encontrados


# Scrapers b√°sicos para sites restantes (mantidos do arquivo original)
def scraper_fenix_melhor_negocio():
    """Scraper b√°sico para Fenix Melhor Neg√≥cio"""
    return scraper_generico("https://fenixmelhornegocio.com.br/", "Fenix Melhor Neg√≥cio")

def scraper_markize():
    """Scraper b√°sico para Markize"""
    return scraper_generico("https://www.markize.com.br/", "Markize")

def scraper_firmesa():
    """Scraper b√°sico para Firmesa"""
    return scraper_generico("https://www.firmesa.com.br/", "Firmesa")

def scraper_padra():
    """Scraper b√°sico para Padra"""
    return scraper_generico("https://padra.com.br/", "Padra")

def scraper_lunardi_imoveis():
    """Scraper b√°sico para Lunardi Im√≥veis"""
    return scraper_generico("https://www.lunardiimoveis.com.br/", "Lunardi Im√≥veis")

def scraper_sim_imoveis_chapeco():
    """Scraper b√°sico para Sim Im√≥veis Chapec√≥"""
    return scraper_generico("https://www.simimoveischapeco.com/", "Sim Im√≥veis Chapec√≥")

def scraper_tucuma_imoveis():
    """Scraper b√°sico para Tucum√£ Im√≥veis"""
    return scraper_generico("https://tucumaimoveis.com.br/", "Tucum√£ Im√≥veis")

def scraper_imobiliaria_chapeco():
    """Scraper b√°sico para Imobili√°ria Chapec√≥"""
    return scraper_generico("https://www.imobiliariachapeco.com.br/", "Imobili√°ria Chapec√≥")


def scraper_generico(url, nome_imobiliaria):
    """
    Scraper gen√©rico para sites com estrutura padr√£o
    """
    try:
        response = requests.get(url, headers=HEADERS, timeout=20)
        response.raise_for_status()
    except requests.exceptions.RequestException as e:
        print(f"Erro ao acessar {nome_imobiliaria}: {e}")
        return []

    soup = BeautifulSoup(response.content, 'html.parser')
    imoveis_encontrados = []
    
    # Buscar por links que possam conter informa√ß√µes de im√≥veis
    all_links = soup.find_all('a', href=True)
    
    for link in all_links:
        text = link.get_text().strip()
        href = link.get('href', '')
        
        # Filtrar links relevantes
        if (len(text) > 20 and 
            ('R$' in text or 'alug' in text.lower() or 'vend' in text.lower() or 'm¬≤' in text or 'quarto' in text)):
            try:
                # URL absoluta
                url_imovel = href
                if href.startswith('/'):
                    base_url = url.rstrip('/')
                    url_imovel = base_url + href
                
                # Extrair c√≥digo
                codigo = ""
                codigo_patterns = [
                    r'cod[igo]*[:\s]*(\d+)',
                    r'#(\d+)',
                    r'/(\d+)/?$',
                    r'ref[erencia]*[:\s]*(\d+)'
                ]
                
                for pattern in codigo_patterns:
                    match = re.search(pattern, text + ' ' + href, re.IGNORECASE)
                    if match:
                        codigo = match.group(1)
                        break
                
                # Extrair pre√ßo
                preco_match = re.search(r'R\$\s*([\d.,]+)', text)
                preco = 'R$ ' + preco_match.group(1) if preco_match else ""
                
                # Extrair tipo do im√≥vel
                tipo_imovel = ""
                if 'apartamento' in text.lower():
                    tipo_imovel = "Apartamento"
                elif 'casa' in text.lower():
                    tipo_imovel = "Casa"
                elif 'terreno' in text.lower():
                    tipo_imovel = "Terreno"
                elif 'sala' in text.lower():
                    tipo_imovel = "Sala Comercial"
                
                # Determinar tipo de neg√≥cio
                tipo_negocio = "VENDA"  # Padr√£o
                if any(word in href.lower() for word in ['alug', 'locar', 'rent']):
                    tipo_negocio = "LOCA√á√ÉO"
                elif any(word in text.lower() for word in ['alug', 'locar', 'loca√ß√£o', 'para alugar']):
                    tipo_negocio = "LOCA√á√ÉO"
                elif preco:
                    valor_numerico = re.sub(r'[^\d]', '', preco)
                    if valor_numerico and int(valor_numerico) < 5000:
                        tipo_negocio = "LOCA√á√ÉO"
                
                # Extrair caracter√≠sticas b√°sicas
                area_match = re.search(r'(\d+)m¬≤', text)
                area = area_match.group(1) + 'm¬≤' if area_match else ""
                
                quartos_match = re.search(r'(\d+)\s*quartos?', text)
                quartos = quartos_match.group(1) if quartos_match else ""
                
                banheiros_match = re.search(r'(\d+)\s*banheiros?', text)
                banheiros = banheiros_match.group(1) if banheiros_match else ""
                
                vagas_match = re.search(r'(\d+)\s*vagas?', text)
                vagas = vagas_match.group(1) if vagas_match else ""
                
                if codigo or preco:  # Adiciona se tiver pelo menos c√≥digo ou pre√ßo
                    imoveis_encontrados.append({
                        "imobiliaria": nome_imobiliaria,
                        "codigo": codigo,
                        "titulo": text[:100] + "..." if len(text) > 100 else text,
                        "tipo_imovel": tipo_imovel,
                        "preco": preco,
                        "area": area,
                        "quartos": quartos,
                        "banheiros": banheiros,
                        "vagas": vagas,
                        "endereco": "Chapec√≥, SC",
                        "tipo_negocio": tipo_negocio,
                        "url": url_imovel
                    })
                    
            except Exception as e:
                print(f"Erro ao processar link do {nome_imobiliaria}: {e}")
                continue
    
    print(f"{nome_imobiliaria}: {len(imoveis_encontrados)} im√≥veis encontrados")
    return imoveis_encontrados


def executar_todos_scrapers():
    """
    Executa todos os scrapers dispon√≠veis
    VERS√ÉO INTEGRADA COM CORRE√á√ïES
    """
    print("=== EXECUTANDO TODOS OS SCRAPERS (VERS√ÉO CORRIGIDA) ===")
    
    todos_imoveis = []
    
    # Lista de todas as fun√ß√µes de scraper
    scrapers = [
        scraper_plaza_chapeco,           # ‚úÖ Funcionando
        scraper_casa_imoveis,            # ‚úÖ Funcionando  
        scraper_santa_maria,             # üîß CORRIGIDO
        scraper_formiga_imoveis,         # üîß CORRIGIDO
        scraper_mobg,                    # ‚úÖ Funcionando
        scraper_smart_aluguel_venda,     # ‚úÖ Funcionando
        scraper_fenix_melhor_negocio,    # B√°sico
        scraper_markize,                 # B√°sico
        scraper_firmesa,                 # B√°sico
        scraper_padra,                   # B√°sico
        scraper_lunardi_imoveis,         # B√°sico
        scraper_sim_imoveis_chapeco,     # B√°sico
        scraper_tucuma_imoveis,          # B√°sico
        scraper_imobiliaria_chapeco      # B√°sico
    ]
    
    for scraper_func in scrapers:
        try:
            nome_scraper = scraper_func.__name__.replace('scraper_', '').replace('_', ' ').title()
            print(f"\n--- Executando {nome_scraper} ---")
            
            imoveis = scraper_func()
            todos_imoveis.extend(imoveis)
            
            print(f"‚úÖ {nome_scraper}: {len(imoveis)} im√≥veis coletados")
            
        except Exception as e:
            nome_scraper = scraper_func.__name__.replace('scraper_', '').replace('_', ' ').title()
            print(f"‚ùå Erro ao executar {nome_scraper}: {e}")
    
    print(f"\n=== TOTAL: {len(todos_imoveis)} im√≥veis coletados de todas as imobili√°rias ===")
    
    # Estat√≠sticas por imobili√°ria
    print("\n=== ESTAT√çSTICAS POR IMOBILI√ÅRIA ===")
    imobiliarias = {}
    for imovel in todos_imoveis:
        nome = imovel['imobiliaria']
        if nome not in imobiliarias:
            imobiliarias[nome] = {'total': 0, 'locacao': 0, 'venda': 0}
        imobiliarias[nome]['total'] += 1
        if imovel['tipo_negocio'] == 'LOCA√á√ÉO':
            imobiliarias[nome]['locacao'] += 1
        else:
            imobiliarias[nome]['venda'] += 1
    
    for nome, stats in imobiliarias.items():
        print(f"{nome}: {stats['total']} total ({stats['locacao']} loca√ß√£o, {stats['venda']} venda)")
    
    return todos_imoveis


# Exemplo de uso
if __name__ == "__main__":
    # Executar todos os scrapers
    imoveis = executar_todos_scrapers()
    
    # Exibir alguns exemplos
    print("\n=== EXEMPLOS DE IM√ìVEIS COLETADOS ===")
    for i, imovel in enumerate(imoveis[:3]):
        print(f"\nIm√≥vel {i+1}:")
        for key, value in imovel.items():
            print(f"{key}: {value}")
        print("-" * 50)

